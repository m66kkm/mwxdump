//! å¹¶è¡Œé¡µé¢è§£å¯†å®ç°
//! 
//! æä¾›é«˜æ€§èƒ½çš„å¼‚æ­¥å¹¶è¡Œè§£å¯†åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡å¤§æ–‡ä»¶è§£å¯†é€Ÿåº¦

use std::collections::BTreeMap;
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use tokio::fs::File;
use tokio::io::{AsyncReadExt, AsyncSeekExt, AsyncWriteExt, SeekFrom};
use tokio::sync::{mpsc, Mutex, Semaphore};
use tracing::{debug, info, warn};
use futures::future::try_join_all;

use crate::errors::{Result, WeChatError};
use super::{
    decrypt_common::{derive_keys_v4, verify_page_hmac, SQLITE_HEADER},
    DecryptConfig, ProgressCallback,
};

/// é¡µé¢å¤„ç†ä»»åŠ¡
#[derive(Debug, Clone)]
pub struct PageTask {
    /// é¡µé¢ç¼–å·
    pub page_num: u64,
    /// æ–‡ä»¶åç§»é‡
    pub offset: u64,
    /// é¡µé¢å¤§å°
    pub size: usize,
    /// é¡µé¢æ•°æ®
    pub data: Vec<u8>,
}

/// å¤„ç†å®Œæˆçš„é¡µé¢
#[derive(Debug)]
pub struct ProcessedPage {
    /// é¡µé¢ç¼–å·
    pub page_num: u64,
    /// å¤„ç†ç»“æœ
    pub result: Result<Vec<u8>>,
}

impl ProcessedPage {
    /// åˆ›å»ºæˆåŠŸçš„å¤„ç†ç»“æœ
    pub fn success(page_num: u64, data: Vec<u8>) -> Self {
        Self {
            page_num,
            result: Ok(data),
        }
    }
    
    /// åˆ›å»ºé”™è¯¯çš„å¤„ç†ç»“æœ
    pub fn error(page_num: u64, error: crate::errors::WeChatError) -> Self {
        Self {
            page_num,
            result: Err(error.into()),
        }
    }
}

/// å¹¶è¡Œè§£å¯†é…ç½®
#[derive(Debug, Clone)]
pub struct ParallelDecryptConfig {
    /// å¹¶å‘é¡µé¢æ•°é‡
    pub concurrent_pages: usize,
    /// æ¯æ‰¹å¤„ç†çš„é¡µé¢æ•°
    pub batch_size: usize,
    /// è¯»å–ç¼“å†²åŒºå¤§å°
    pub read_buffer_size: usize,
    /// å†™å…¥ç¼“å†²åŒºå¤§å°
    pub write_buffer_size: usize,
    /// å†…å­˜ä½¿ç”¨é™åˆ¶ (MB)
    pub max_memory_mb: usize,
}

impl ParallelDecryptConfig {
    /// è‡ªåŠ¨é…ç½®å‚æ•°
    pub fn auto_configure() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            concurrent_pages: (cpu_count * 2).min(32).max(4),
            batch_size: 64,
            read_buffer_size: 1024 * 1024, // 1MB
            write_buffer_size: 1024 * 1024, // 1MB
            max_memory_mb: 512, // 512MB
        }
    }
    
    /// ä¸ºå°æ–‡ä»¶ä¼˜åŒ–çš„é…ç½®
    pub fn small_file_config() -> Self {
        Self {
            concurrent_pages: 4,
            batch_size: 16,
            read_buffer_size: 256 * 1024, // 256KB
            write_buffer_size: 256 * 1024, // 256KB
            max_memory_mb: 128, // 128MB
        }
    }
    
    /// ä¸ºå¤§æ–‡ä»¶ä¼˜åŒ–çš„é…ç½®
    pub fn large_file_config() -> Self {
        let cpu_count = num_cpus::get();
        Self {
            concurrent_pages: (cpu_count * 4).min(64).max(8),
            batch_size: 128,
            read_buffer_size: 2 * 1024 * 1024, // 2MB
            write_buffer_size: 2 * 1024 * 1024, // 2MB
            max_memory_mb: 1024, // 1GB
        }
    }
}

/// å†…å­˜ä½¿ç”¨ç›‘æ§å™¨
pub struct MemoryMonitor {
    max_memory_bytes: usize,
    current_usage: Arc<AtomicUsize>,
}

impl MemoryMonitor {
    pub fn new(max_memory_mb: usize) -> Self {
        Self {
            max_memory_bytes: max_memory_mb * 1024 * 1024,
            current_usage: Arc::new(AtomicUsize::new(0)),
        }
    }
    
    pub fn allocate(&self, size: usize) -> bool {
        let current = self.current_usage.fetch_add(size, Ordering::Relaxed);
        current + size <= self.max_memory_bytes
    }
    
    pub fn deallocate(&self, size: usize) {
        self.current_usage.fetch_sub(size, Ordering::Relaxed);
    }
    
    pub fn current_usage_mb(&self) -> usize {
        self.current_usage.load(Ordering::Relaxed) / (1024 * 1024)
    }
    
    pub fn is_memory_pressure(&self) -> bool {
        let current = self.current_usage.load(Ordering::Relaxed);
        current > (self.max_memory_bytes * 80 / 100) // 80% é˜ˆå€¼
    }
}

/// å¹¶è¡Œè§£å¯†å™¨
pub struct ParallelDecryptor {
    config: DecryptConfig,
    parallel_config: ParallelDecryptConfig,
    memory_monitor: MemoryMonitor,
}

impl ParallelDecryptor {
    /// åˆ›å»ºæ–°çš„å¹¶è¡Œè§£å¯†å™¨
    pub fn new(config: DecryptConfig, parallel_config: ParallelDecryptConfig) -> Self {
        let memory_monitor = MemoryMonitor::new(parallel_config.max_memory_mb);
        Self {
            config,
            parallel_config,
            memory_monitor,
        }
    }
    
    /// å¹¶è¡Œè§£å¯†æ•°æ®åº“
    pub async fn decrypt_database_parallel(
        &self,
        input_path: &std::path::Path,
        output_path: &std::path::Path,
        key: &[u8],
        progress_callback: Option<ProgressCallback>,
    ) -> Result<()> {
        info!("ğŸš€ å¼€å§‹å¹¶è¡Œè§£å¯†: {:?} -> {:?}", input_path, output_path);
        info!("âš™ï¸ å¹¶å‘é…ç½®: {} ä¸ªå·¥ä½œçº¿ç¨‹, æ‰¹å¤§å°: {}", 
              self.parallel_config.concurrent_pages, 
              self.parallel_config.batch_size);
        
        let start_time = std::time::Instant::now();
        
        // 1. è¯»å–æ–‡ä»¶ä¿¡æ¯
        let (file_size, first_page) = self.read_db_info(input_path).await?;
        let total_pages = (file_size as usize + self.config.page_size - 1) / self.config.page_size;
        
        info!("ğŸ“Š æ–‡ä»¶ä¿¡æ¯: å¤§å° {} MB, æ€»é¡µæ•° {}", 
              file_size / (1024 * 1024), total_pages);
        
        // 2. éªŒè¯å’Œå‡†å¤‡å¯†é’¥
        let derived_keys = self.prepare_keys(&first_page, key).await?;
        let derived_keys = Arc::new(derived_keys);
        
        // 3. åˆ›å»ºæ–‡ä»¶å¥æŸ„
        let input_file = Arc::new(Mutex::new(File::open(input_path).await?));
        let output_file = Arc::new(Mutex::new(File::create(output_path).await?));
        
        // 4. å†™å…¥SQLiteå¤´
        output_file.lock().await.write_all(SQLITE_HEADER).await?;
        
        // 5. åˆ›å»ºé€šä¿¡é€šé“
        let (page_sender, page_receiver) = mpsc::channel(self.parallel_config.batch_size * 2);
        let (result_sender, result_receiver) = mpsc::channel(self.parallel_config.batch_size * 2);
        
        // 6. å¯åŠ¨ä»»åŠ¡
        let read_task = self.spawn_read_task(
            input_file.clone(),
            page_sender,
            total_pages,
        );
        
        let process_tasks = self.spawn_process_tasks(
            page_receiver,
            result_sender,
            derived_keys,
        ).await?;
        
        let write_task = self.spawn_write_task(
            output_file,
            result_receiver,
            total_pages,
            progress_callback,
        );
        
        // 7. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        let (read_result, process_results, write_result) = tokio::try_join!(
            read_task,
            try_join_all(process_tasks),
            write_task
        )?;
        
        let elapsed = start_time.elapsed();
        info!("ğŸ‰ å¹¶è¡Œè§£å¯†å®Œæˆ! è€—æ—¶: {:.2}ç§’", elapsed.as_secs_f64());
        info!("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡: è¯»å– {} é¡µ, å¤„ç† {} ä¸ªä»»åŠ¡, å†™å…¥ {} é¡µ", 
              read_result?, process_results.len(), write_result?);
        info!("ğŸ’¾ å†…å­˜ä½¿ç”¨å³°å€¼: {} MB", self.memory_monitor.current_usage_mb());
        
        Ok(())
    }
    
    /// è¯»å–æ•°æ®åº“æ–‡ä»¶ä¿¡æ¯
    async fn read_db_info(&self, file_path: &std::path::Path) -> Result<(u64, Vec<u8>)> {
        let mut file = File::open(file_path).await
            .map_err(|e| WeChatError::DecryptionFailed(format!("æ‰“å¼€æ–‡ä»¶å¤±è´¥: {}", e)))?;
        
        // è·å–æ–‡ä»¶å¤§å°
        let file_size = file.metadata().await
            .map_err(|e| WeChatError::DecryptionFailed(format!("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {}", e)))?
            .len();
        
        // è¯»å–ç¬¬ä¸€é¡µ
        let mut first_page = vec![0u8; self.config.page_size];
        let bytes_read = file.read(&mut first_page).await
            .map_err(|e| WeChatError::DecryptionFailed(format!("è¯»å–ç¬¬ä¸€é¡µå¤±è´¥: {}", e)))?;
        
        if bytes_read < self.config.page_size {
            first_page.truncate(bytes_read);
        }
        
        Ok((file_size, first_page))
    }
    
    /// å‡†å¤‡è§£å¯†å¯†é’¥
    async fn prepare_keys(&self, first_page: &[u8], key: &[u8]) -> Result<super::decrypt_common::DerivedKeys> {
        use super::decrypt_common::{is_database_encrypted, SALT_SIZE};
        
        // æ£€æŸ¥æ˜¯å¦å·²è§£å¯†
        if !is_database_encrypted(first_page) {
            return Err(WeChatError::DecryptionFailed("æ•°æ®åº“å·²ç»è§£å¯†".to_string()).into());
        }
        
        // æå–Salt
        if first_page.len() < SALT_SIZE {
            return Err(WeChatError::DecryptionFailed("ç¬¬ä¸€é¡µæ•°æ®ä¸å®Œæ•´".to_string()).into());
        }
        
        let salt = &first_page[..SALT_SIZE];
        debug!("æå–Salt: {} å­—èŠ‚", salt.len());
        
        // æ´¾ç”Ÿå¯†é’¥
        let derived_keys = derive_keys_v4(key, salt)?;
        
        // éªŒè¯å¯†é’¥
        if !verify_page_hmac(first_page, &derived_keys.mac_key, 0, &self.config)? {
            return Err(WeChatError::DecryptionFailed("å¯†é’¥éªŒè¯å¤±è´¥".to_string()).into());
        }
        
        info!("âœ… å¯†é’¥éªŒè¯æˆåŠŸ");
        Ok(derived_keys)
    }
    
    /// å¯åŠ¨è¯»å–ä»»åŠ¡
    fn spawn_read_task(
        &self,
        input_file: Arc<Mutex<File>>,
        sender: mpsc::Sender<PageTask>,
        total_pages: usize,
    ) -> tokio::task::JoinHandle<Result<usize>> {
        let page_size = self.config.page_size;
        let batch_size = self.parallel_config.batch_size;
        let memory_monitor = Arc::new(self.memory_monitor.current_usage.clone());
        
        tokio::spawn(async move {
            let mut pages_read = 0;
            let mut current_batch = Vec::with_capacity(batch_size);
            
            for page_num in 0..total_pages {
                let offset = page_num * page_size;
                
                // å†…å­˜å‹åŠ›æ£€æŸ¥
                while memory_monitor.load(Ordering::Relaxed) > 800 * 1024 * 1024 { // 800MB
                    tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
                }
                
                // è¯»å–é¡µé¢æ•°æ®
                let mut page_data = vec![0u8; page_size];
                let bytes_read = {
                    let mut file = input_file.lock().await;
                    file.seek(SeekFrom::Start(offset as u64)).await?;
                    file.read(&mut page_data).await?
                };
                
                if bytes_read == 0 {
                    break;
                }
                
                if bytes_read < page_size {
                    page_data.truncate(bytes_read);
                }
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºç©ºé¡µé¢ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡è§£å¯†å¤„ç†
                let _is_empty_page = page_data.iter().all(|&b| b == 0);
                
                let task = PageTask {
                    page_num: page_num as u64,
                    offset: offset as u64,
                    size: bytes_read,
                    data: page_data,
                };
                
                current_batch.push(task);
                
                // æ‰¹é‡å‘é€
                if current_batch.len() >= batch_size || page_num == total_pages - 1 {
                    for task in current_batch.drain(..) {
                        sender.send(task).await.map_err(|_| {
                            WeChatError::DecryptionFailed("å‘é€é¡µé¢ä»»åŠ¡å¤±è´¥".to_string())
                        })?;
                        pages_read += 1;
                    }
                    
                    // è®©å‡ºæ§åˆ¶æƒ
                    if pages_read % (batch_size * 4) == 0 {
                        tokio::task::yield_now().await;
                    }
                }
            }
            
            debug!("è¯»å–ä»»åŠ¡å®Œæˆ: {} é¡µ", pages_read);
            Ok(pages_read)
        })
    }
    
    /// å¯åŠ¨å¤„ç†ä»»åŠ¡æ± 
    async fn spawn_process_tasks(
        &self,
        receiver: mpsc::Receiver<PageTask>,
        sender: mpsc::Sender<ProcessedPage>,
        derived_keys: Arc<super::decrypt_common::DerivedKeys>,
    ) -> Result<Vec<tokio::task::JoinHandle<Result<usize>>>> {
        let semaphore = Arc::new(Semaphore::new(self.parallel_config.concurrent_pages));
        let receiver = Arc::new(Mutex::new(receiver));
        let mut tasks = Vec::new();
        
        for worker_id in 0..self.parallel_config.concurrent_pages {
            let receiver = receiver.clone();
            let sender = sender.clone();
            let keys = derived_keys.clone();
            let sem = semaphore.clone();
            let decrypt_config = self.config.clone();
            
            let task = tokio::spawn(async move {
                let mut processed = 0;
                
                loop {
                    let page_task = {
                        let mut rx = receiver.lock().await;
                        match rx.recv().await {
                            Some(task) => task,
                            None => break, // é€šé“å…³é—­
                        }
                    };
                    
                    let _permit = sem.acquire().await.unwrap();
                    let page_num = page_task.page_num; // ä¿å­˜é¡µé¢ç¼–å·
                    
                    match Self::process_page_async(page_task, &keys, &decrypt_config).await {
                        Ok(processed_page) => {
                            sender.send(processed_page).await.map_err(|_| {
                                WeChatError::DecryptionFailed("å‘é€å¤„ç†ç»“æœå¤±è´¥".to_string())
                            })?;
                            processed += 1;
                        }
                        Err(e) => {
                            warn!("Worker {} å¤„ç†é¡µé¢å¤±è´¥: {}", worker_id, e);
                            // å‘é€é”™è¯¯é¡µé¢ï¼Œä¿æŒé¡ºåº
                            let error_page = ProcessedPage::error(page_num,
                                WeChatError::DecryptionFailed(format!("é¡µé¢å¤„ç†å¤±è´¥: {}", e)));
                            sender.send(error_page).await.ok();
                        }
                    }
                    
                    // å®šæœŸè®©å‡ºæ§åˆ¶æƒ
                    if processed % 10 == 0 {
                        tokio::task::yield_now().await;
                    }
                }
                
                debug!("Worker {} å®Œæˆ: å¤„ç† {} é¡µ", worker_id, processed);
                Ok(processed)
            });
            
            tasks.push(task);
        }
        
        Ok(tasks)
    }
    
    /// å¼‚æ­¥å¤„ç†å•ä¸ªé¡µé¢
    async fn process_page_async(
        page_task: PageTask,
        keys: &super::decrypt_common::DerivedKeys,
        config: &DecryptConfig,
    ) -> Result<ProcessedPage> {
        let page_num = page_task.page_num;
        let page_data = page_task.data;
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºç©ºé¡µé¢
        if page_data.iter().all(|&b| b == 0) {
            debug!("è·³è¿‡ç©ºé¡µé¢ {}", page_num);
            return Ok(ProcessedPage::success(page_num, page_data));
        }
        
        // å…‹éš†æ•°æ®ç”¨äºé”™è¯¯å¤„ç†
        let page_data_backup = page_data.clone();
        
        // åœ¨ä¸“ç”¨çº¿ç¨‹ä¸­æ‰§è¡ŒCPUå¯†é›†å‹æ“ä½œ
        let enc_key = keys.enc_key.clone();
        let mac_key = keys.mac_key.clone();
        let config = config.clone();
        
        let result = tokio::task::spawn_blocking(move || {
            use super::decrypt_common::decrypt_page;
            decrypt_page(&page_data, &enc_key, &mac_key, page_num, &config)
        }).await;
        
        match result {
            Ok(Ok(decrypted_data)) => {
                debug!("é¡µé¢ {} è§£å¯†æˆåŠŸ", page_num);
                Ok(ProcessedPage::success(page_num, decrypted_data))
            }
            Ok(Err(e)) => {
                warn!("é¡µé¢ {} è§£å¯†å¤±è´¥: {}", page_num, e);
                // å¯¹äºè§£å¯†å¤±è´¥çš„é¡µé¢ï¼Œè¿”å›åŸå§‹æ•°æ®ä½œä¸ºå¤‡ç”¨
                Ok(ProcessedPage::success(page_num, page_data_backup))
            }
            Err(e) => {
                warn!("é¡µé¢ {} å¤„ç†ä»»åŠ¡å¤±è´¥: {}", page_num, e);
                Err(WeChatError::DecryptionFailed(format!("é¡µé¢ {} å¤„ç†ä»»åŠ¡å¤±è´¥: {}", page_num, e)).into())
            }
        }
    }
    
    /// å¯åŠ¨å†™å…¥ä»»åŠ¡
    fn spawn_write_task(
        &self,
        output_file: Arc<Mutex<File>>,
        mut receiver: mpsc::Receiver<ProcessedPage>,
        total_pages: usize,
        progress_callback: Option<ProgressCallback>,
    ) -> tokio::task::JoinHandle<Result<usize>> {
        tokio::spawn(async move {
            let mut pages_written = 0;
            let mut pending_pages = BTreeMap::new();
            let mut next_expected_page = 0u64;
            let mut last_progress_report = std::time::Instant::now();
            
            while let Some(processed_page) = receiver.recv().await {
                pending_pages.insert(processed_page.page_num, processed_page);
                
                // æŒ‰é¡ºåºå†™å…¥è¿ç»­çš„é¡µé¢
                while let Some(page) = pending_pages.remove(&next_expected_page) {
                    match page.result {
                        Ok(data) => {
                            output_file.lock().await.write_all(&data).await?;
                            pages_written += 1;
                            
                            // è°ƒç”¨è¿›åº¦å›è°ƒ
                            if let Some(ref callback) = progress_callback {
                                callback(pages_written as u64, total_pages as u64);
                            }
                            
                            // å®šæœŸæŠ¥å‘Šè¿›åº¦
                            if last_progress_report.elapsed().as_secs() >= 2 {
                                let progress = (pages_written as f64 / total_pages as f64) * 100.0;
                                info!("ğŸ“ˆ è§£å¯†è¿›åº¦: {:.1}% ({}/{})", progress, pages_written, total_pages);
                                last_progress_report = std::time::Instant::now();
                            }
                        }
                        Err(e) => {
                            warn!("é¡µé¢ {} å†™å…¥å¤±è´¥: {}", next_expected_page, e);
                            // å†™å…¥å ä½æ•°æ®
                            let placeholder = vec![0u8; 4096];
                            output_file.lock().await.write_all(&placeholder).await?;
                            pages_written += 1;
                        }
                    }
                    
                    next_expected_page += 1;
                    
                    // å®šæœŸåˆ·æ–°ç¼“å†²åŒº
                    if pages_written % 100 == 0 {
                        output_file.lock().await.flush().await?;
                        tokio::task::yield_now().await;
                    }
                }
            }
            
            // æœ€ç»ˆåˆ·æ–°
            output_file.lock().await.flush().await?;
            debug!("å†™å…¥ä»»åŠ¡å®Œæˆ: {} é¡µ", pages_written);
            Ok(pages_written)
        })
    }
    
    /// è·å–å†…å­˜ç›‘æ§å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    #[cfg(test)]
    pub fn memory_monitor(&self) -> &MemoryMonitor {
        &self.memory_monitor
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_parallel_config() {
        let config = ParallelDecryptConfig::auto_configure();
        assert!(config.concurrent_pages >= 4);
        assert!(config.batch_size > 0);
        assert!(config.max_memory_mb > 0);
    }
    
    #[test]
    fn test_memory_monitor() {
        let monitor = MemoryMonitor::new(100); // 100MB
        assert!(monitor.allocate(50 * 1024 * 1024)); // 50MB
        assert!(monitor.current_usage_mb() < 100);
        monitor.deallocate(50 * 1024 * 1024);
        assert_eq!(monitor.current_usage_mb(), 0);
    }
    
    #[tokio::test]
    async fn test_page_task_creation() {
        let task = PageTask {
            page_num: 1,
            offset: 4096,
            size: 4096,
            data: vec![0u8; 4096],
        };
        assert_eq!(task.page_num, 1);
        assert_eq!(task.offset, 4096);
        assert_eq!(task.size, 4096);
    }
}