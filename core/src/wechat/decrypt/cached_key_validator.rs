//! ç¼“å­˜å¯†é’¥éªŒè¯å™¨
//! 
//! é€šè¿‡ç¼“å­˜PBKDF2è®¡ç®—ç»“æœæ¥æ˜¾è‘—æå‡å¯†é’¥éªŒè¯æ€§èƒ½

use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::sync::atomic::{AtomicU64, Ordering};
use tokio::sync::RwLock;
use blake3::Hash;
use tracing::{debug, info, warn};

use crate::errors::Result;
use super::{
    DecryptVersion, 
    decrypt_common::{derive_keys_v4, DerivedKeys, SALT_SIZE},
    decrypt_validator::KeyValidator,
};

/// ç¼“å­˜é”®ï¼Œç”¨äºå”¯ä¸€æ ‡è¯†å¯†é’¥å’ŒSaltçš„ç»„åˆ
#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct CacheKey {
    /// å¯†é’¥å“ˆå¸Œ
    key_hash: Hash,
    /// Saltå“ˆå¸Œ
    salt_hash: Hash,
}

impl CacheKey {
    /// åˆ›å»ºæ–°çš„ç¼“å­˜é”®
    pub fn new(key: &[u8], salt: &[u8]) -> Self {
        Self {
            key_hash: blake3::hash(key),
            salt_hash: blake3::hash(salt),
        }
    }
}

/// éªŒè¯ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Default)]
pub struct ValidationStats {
    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: AtomicU64,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: AtomicU64,
    /// æ€»éªŒè¯æ¬¡æ•°
    pub total_validations: AtomicU64,
    /// PBKDF2è®¡ç®—æ¬¡æ•°
    pub pbkdf2_computations: AtomicU64,
}

impl ValidationStats {
    /// è·å–ç¼“å­˜å‘½ä¸­ç‡
    pub fn cache_hit_rate(&self) -> f64 {
        let hits = self.cache_hits.load(Ordering::Relaxed) as f64;
        let total = self.total_validations.load(Ordering::Relaxed) as f64;
        if total > 0.0 { hits / total * 100.0 } else { 0.0 }
    }
    
    /// è®°å½•ç¼“å­˜å‘½ä¸­
    pub fn record_cache_hit(&self) {
        self.cache_hits.fetch_add(1, Ordering::Relaxed);
        self.total_validations.fetch_add(1, Ordering::Relaxed);
    }
    
    /// è®°å½•ç¼“å­˜æœªå‘½ä¸­
    pub fn record_cache_miss(&self) {
        self.cache_misses.fetch_add(1, Ordering::Relaxed);
        self.total_validations.fetch_add(1, Ordering::Relaxed);
    }
    
    /// è®°å½•PBKDF2è®¡ç®—
    pub fn record_pbkdf2_computation(&self) {
        self.pbkdf2_computations.fetch_add(1, Ordering::Relaxed);
    }
}

/// æ‰¹é‡éªŒè¯ç»“æœ
#[derive(Debug)]
pub struct BatchValidationResult {
    /// æ¯ä¸ªæ–‡ä»¶çš„éªŒè¯ç»“æœ
    pub results: HashMap<PathBuf, Option<DecryptVersion>>,
    /// ç¼“å­˜çš„æ´¾ç”Ÿå¯†é’¥
    pub derived_keys: HashMap<CacheKey, DerivedKeys>,
    /// ç»Ÿè®¡ä¿¡æ¯
    pub stats: ValidationStats,
}

/// ç¼“å­˜é…ç½®
#[derive(Debug, Clone)]
pub struct CacheConfig {
    /// æœ€å¤§å†…å­˜ç¼“å­˜æ¡ç›®æ•°
    pub max_memory_entries: usize,
    /// æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
    pub enable_verbose_logging: bool,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            max_memory_entries: 1000,
            enable_verbose_logging: false,
        }
    }
}

/// ç¼“å­˜çš„å¯†é’¥éªŒè¯å™¨
pub struct CachedKeyValidator {
    /// å¯†é’¥ç¼“å­˜ï¼šCacheKey -> DerivedKeys
    cache: Arc<RwLock<HashMap<CacheKey, DerivedKeys>>>,
    /// ç‰ˆæœ¬ç¼“å­˜ï¼šCacheKey -> DecryptVersion
    version_cache: Arc<RwLock<HashMap<CacheKey, DecryptVersion>>>,
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<ValidationStats>,
    /// é…ç½®
    config: CacheConfig,
    /// å›é€€éªŒè¯å™¨
    fallback_validator: KeyValidator,
}

impl CachedKeyValidator {
    /// åˆ›å»ºæ–°çš„ç¼“å­˜å¯†é’¥éªŒè¯å™¨
    pub fn new(config: CacheConfig) -> Self {
        Self {
            cache: Arc::new(RwLock::new(HashMap::new())),
            version_cache: Arc::new(RwLock::new(HashMap::new())),
            stats: Arc::new(ValidationStats::default()),
            config,
            fallback_validator: KeyValidator::new(),
        }
    }
    
    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»º
    pub fn with_default_config() -> Self {
        Self::new(CacheConfig::default())
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn stats(&self) -> &ValidationStats {
        &self.stats
    }
    
    /// æ¸…ç©ºç¼“å­˜
    pub async fn clear_cache(&self) {
        let mut cache = self.cache.write().await;
        let mut version_cache = self.version_cache.write().await;
        cache.clear();
        version_cache.clear();
        info!("ğŸ§¹ ç¼“å­˜å·²æ¸…ç©º");
    }
    
    /// è·å–ç¼“å­˜å¤§å°
    pub async fn cache_size(&self) -> usize {
        let cache = self.cache.read().await;
        cache.len()
    }
    
    /// å•ä¸ªæ–‡ä»¶å¯†é’¥éªŒè¯ï¼ˆå¸¦ç¼“å­˜ï¼‰
    pub async fn validate_key_cached(
        &self,
        db_path: &Path,
        key: &[u8],
    ) -> Result<Option<DecryptVersion>> {
        if self.config.enable_verbose_logging {
            debug!("ğŸ” å¼€å§‹ç¼“å­˜å¯†é’¥éªŒè¯: {:?}", db_path);
        }
        
        // è¯»å–Salt
        let salt = match self.read_file_salt(db_path).await {
            Ok(salt) => salt,
            Err(e) => {
                warn!("âš ï¸ è¯»å–Saltå¤±è´¥: {:?} - {}", db_path, e);
                // å›é€€åˆ°åŸå§‹éªŒè¯å™¨
                return self.fallback_validator.validate_key_auto(db_path, key).await;
            }
        };
        
        let cache_key = CacheKey::new(key, &salt);
        
        // æ£€æŸ¥ç‰ˆæœ¬ç¼“å­˜
        {
            let version_cache = self.version_cache.read().await;
            if let Some(&version) = version_cache.get(&cache_key) {
                self.stats.record_cache_hit();
                if self.config.enable_verbose_logging {
                    debug!("âœ… ç‰ˆæœ¬ç¼“å­˜å‘½ä¸­: {:?}", version);
                }
                return Ok(Some(version));
            }
        }
        
        // æ£€æŸ¥å¯†é’¥ç¼“å­˜
        let derived_keys = {
            let cache = self.cache.read().await;
            if let Some(keys) = cache.get(&cache_key) {
                self.stats.record_cache_hit();
                if self.config.enable_verbose_logging {
                    debug!("âœ… å¯†é’¥ç¼“å­˜å‘½ä¸­");
                }
                keys.clone()
            } else {
                self.stats.record_cache_miss();
                drop(cache);
                
                // è®¡ç®—æ–°çš„æ´¾ç”Ÿå¯†é’¥
                if self.config.enable_verbose_logging {
                    debug!("ğŸ”„ è®¡ç®—æ–°çš„æ´¾ç”Ÿå¯†é’¥");
                }
                
                self.stats.record_pbkdf2_computation();
                let keys = self.compute_derived_keys_async(key, &salt).await?;
                
                // å­˜å…¥ç¼“å­˜
                self.store_in_cache(cache_key.clone(), keys.clone()).await;
                keys
            }
        };
        
        // éªŒè¯HMAC
        let version = match self.verify_hmac_with_keys(db_path, &derived_keys).await {
            Ok(true) => {
                let version = DecryptVersion::V4; // ç›®å‰åªæ”¯æŒV4
                
                // å­˜å…¥ç‰ˆæœ¬ç¼“å­˜
                {
                    let mut version_cache = self.version_cache.write().await;
                    version_cache.insert(cache_key, version);
                }
                
                if self.config.enable_verbose_logging {
                    debug!("âœ… HMACéªŒè¯æˆåŠŸ: {:?}", version);
                }
                Some(version)
            }
            Ok(false) => {
                if self.config.enable_verbose_logging {
                    debug!("âŒ HMACéªŒè¯å¤±è´¥");
                }
                None
            }
            Err(e) => {
                warn!("âš ï¸ HMACéªŒè¯å‡ºé”™: {} - å›é€€åˆ°åŸå§‹éªŒè¯å™¨", e);
                return self.fallback_validator.validate_key_auto(db_path, key).await;
            }
        };
        
        Ok(version)
    }
    
    /// æ‰¹é‡éªŒè¯å¤šä¸ªæ–‡ä»¶
    pub async fn validate_files_batch(
        &self,
        files: &[PathBuf],
        key: &[u8],
    ) -> Result<BatchValidationResult> {
        info!("ğŸš€ å¼€å§‹æ‰¹é‡å¯†é’¥éªŒè¯: {} ä¸ªæ–‡ä»¶", files.len());
        let start_time = std::time::Instant::now();
        
        // 1. å¹¶è¡Œè¯»å–æ‰€æœ‰Salt
        let salts = self.read_salts_parallel(files).await?;
        
        // 2. æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„CacheKey
        let mut unique_keys = HashMap::new();
        let mut file_to_cache_key = HashMap::new();
        
        for (file, salt) in &salts {
            let cache_key = CacheKey::new(key, salt);
            unique_keys.insert(cache_key.clone(), salt.clone());
            file_to_cache_key.insert(file.clone(), cache_key);
        }
        
        info!("ğŸ“Š å‘ç° {} ä¸ªå”¯ä¸€çš„å¯†é’¥-Saltç»„åˆ", unique_keys.len());
        
        // 3. æ‰¹é‡è®¡ç®—ç¼ºå¤±çš„æ´¾ç”Ÿå¯†é’¥
        let derived_keys = self.compute_missing_keys_batch(key, &unique_keys).await?;
        
        // 4. æ‰¹é‡éªŒè¯HMAC
        let mut results = HashMap::new();
        for (file, cache_key) in file_to_cache_key {
            if let Some(keys) = derived_keys.get(&cache_key) {
                match self.verify_hmac_with_keys(&file, keys).await {
                    Ok(true) => {
                        results.insert(file, Some(DecryptVersion::V4));
                    }
                    Ok(false) => {
                        results.insert(file, None);
                    }
                    Err(e) => {
                        warn!("âš ï¸ æ–‡ä»¶ {:?} HMACéªŒè¯å‡ºé”™: {}", file, e);
                        results.insert(file, None);
                    }
                }
            } else {
                results.insert(file, None);
            }
        }
        
        let elapsed = start_time.elapsed();
        info!("ğŸ‰ æ‰¹é‡éªŒè¯å®Œæˆ! è€—æ—¶: {:.2}ç§’", elapsed.as_secs_f64());
        info!("ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {:.1}%", self.stats.cache_hit_rate());
        
        Ok(BatchValidationResult {
            results,
            derived_keys,
            stats: ValidationStats::default(), // è¿”å›å½“å‰ç»Ÿè®¡çš„å¿«ç…§
        })
    }
    
    /// å¼‚æ­¥è®¡ç®—æ´¾ç”Ÿå¯†é’¥
    async fn compute_derived_keys_async(&self, key: &[u8], salt: &[u8]) -> Result<DerivedKeys> {
        let key = key.to_vec();
        let salt = salt.to_vec();
        
        tokio::task::spawn_blocking(move || {
            derive_keys_v4(&key, &salt)
        }).await?
    }
    
    /// å­˜å‚¨åˆ°ç¼“å­˜
    async fn store_in_cache(&self, cache_key: CacheKey, derived_keys: DerivedKeys) {
        let mut cache = self.cache.write().await;
        
        // æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        if cache.len() >= self.config.max_memory_entries {
            // ç®€å•çš„LRUç­–ç•¥ï¼šæ¸…ç©ºä¸€åŠç¼“å­˜
            let keys_to_remove: Vec<_> = cache.keys().take(cache.len() / 2).cloned().collect();
            for key in keys_to_remove {
                cache.remove(&key);
            }
            debug!("ğŸ§¹ ç¼“å­˜å·²æ¸…ç†ï¼Œå½“å‰å¤§å°: {}", cache.len());
        }
        
        cache.insert(cache_key, derived_keys);
    }
    
    /// è¯»å–æ–‡ä»¶çš„Salt
    async fn read_file_salt(&self, file_path: &Path) -> Result<Vec<u8>> {
        use tokio::fs::File;
        use tokio::io::AsyncReadExt;
        
        let mut file = File::open(file_path).await?;
        let mut salt = vec![0u8; SALT_SIZE];
        file.read_exact(&mut salt).await?;
        Ok(salt)
    }
    
    /// å¹¶è¡Œè¯»å–å¤šä¸ªæ–‡ä»¶çš„Salt
    async fn read_salts_parallel(&self, files: &[PathBuf]) -> Result<HashMap<PathBuf, Vec<u8>>> {
        use futures::future::try_join_all;
        
        let tasks = files.iter().map(|file| {
            let file = file.clone();
            async move {
                let salt = self.read_file_salt(&file).await?;
                Ok::<(PathBuf, Vec<u8>), anyhow::Error>((file, salt))
            }
        });
        
        let results = try_join_all(tasks).await?;
        Ok(results.into_iter().collect())
    }
    
    /// æ‰¹é‡è®¡ç®—ç¼ºå¤±çš„æ´¾ç”Ÿå¯†é’¥
    async fn compute_missing_keys_batch(
        &self,
        key: &[u8],
        unique_keys: &HashMap<CacheKey, Vec<u8>>,
    ) -> Result<HashMap<CacheKey, DerivedKeys>> {
        let mut result = HashMap::new();
        let mut missing_keys = Vec::new();
        
        // æ£€æŸ¥ç¼“å­˜ä¸­å·²æœ‰çš„å¯†é’¥
        {
            let cache = self.cache.read().await;
            for (cache_key, _salt) in unique_keys {
                if let Some(keys) = cache.get(cache_key) {
                    result.insert(cache_key.clone(), keys.clone());
                    self.stats.record_cache_hit();
                } else {
                    missing_keys.push(cache_key.clone());
                    self.stats.record_cache_miss();
                }
            }
        }
        
        if !missing_keys.is_empty() {
            info!("ğŸ”„ éœ€è¦è®¡ç®— {} ä¸ªæ–°çš„æ´¾ç”Ÿå¯†é’¥", missing_keys.len());
            
            // å¹¶è¡Œè®¡ç®—ç¼ºå¤±çš„å¯†é’¥
            let tasks = missing_keys.iter().map(|cache_key| {
                let salt = unique_keys.get(cache_key).unwrap().clone();
                let key = key.to_vec();
                let cache_key = cache_key.clone();
                
                async move {
                    self.stats.record_pbkdf2_computation();
                    let derived_keys = self.compute_derived_keys_async(&key, &salt).await?;
                    Ok::<(CacheKey, DerivedKeys), anyhow::Error>((cache_key, derived_keys))
                }
            });
            
            let computed_results = futures::future::try_join_all(tasks).await?;
            
            // å­˜å‚¨åˆ°ç¼“å­˜å¹¶æ·»åŠ åˆ°ç»“æœ
            for (cache_key, derived_keys) in computed_results {
                self.store_in_cache(cache_key.clone(), derived_keys.clone()).await;
                result.insert(cache_key, derived_keys);
            }
        }
        
        Ok(result)
    }
    
    /// ä½¿ç”¨æ´¾ç”Ÿå¯†é’¥éªŒè¯HMAC
    async fn verify_hmac_with_keys(&self, db_path: &Path, derived_keys: &DerivedKeys) -> Result<bool> {
        use tokio::fs::File;
        use tokio::io::AsyncReadExt;
        use super::decrypt_common::verify_page_hmac;
        use crate::wechat::decrypt::DecryptConfig;
        
        let mut file = File::open(db_path).await?;
        let config = DecryptConfig::v4();
        let mut first_page = vec![0u8; config.page_size];
        let bytes_read = file.read(&mut first_page).await?;
        
        if bytes_read < config.page_size {
            first_page.truncate(bytes_read);
        }
        
        verify_page_hmac(&first_page, &derived_keys.mac_key, 0, &config)
    }
}

impl Default for CachedKeyValidator {
    fn default() -> Self {
        Self::with_default_config()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;
    use std::io::Write;
    
    #[tokio::test]
    async fn test_cache_key_creation() {
        let key = b"test_key_32_bytes_long_for_test!";
        let salt = b"test_salt_16byte";
        
        let cache_key1 = CacheKey::new(key, salt);
        let cache_key2 = CacheKey::new(key, salt);
        
        assert_eq!(cache_key1, cache_key2);
    }
    
    #[tokio::test]
    async fn test_validation_stats() {
        let stats = ValidationStats::default();
        
        stats.record_cache_hit();
        stats.record_cache_miss();
        stats.record_pbkdf2_computation();
        
        assert_eq!(stats.cache_hits.load(Ordering::Relaxed), 1);
        assert_eq!(stats.cache_misses.load(Ordering::Relaxed), 1);
        assert_eq!(stats.total_validations.load(Ordering::Relaxed), 2);
        assert_eq!(stats.pbkdf2_computations.load(Ordering::Relaxed), 1);
        assert_eq!(stats.cache_hit_rate(), 50.0);
    }
    
    #[tokio::test]
    async fn test_cached_validator_creation() {
        let validator = CachedKeyValidator::with_default_config();
        assert_eq!(validator.cache_size().await, 0);
        assert_eq!(validator.stats().cache_hit_rate(), 0.0);
    }
    
    #[tokio::test]
    async fn test_cache_clear() {
        let validator = CachedKeyValidator::with_default_config();
        
        // æ¨¡æ‹Ÿæ·»åŠ ä¸€äº›ç¼“å­˜é¡¹
        let cache_key = CacheKey::new(b"test", b"salt");
        // è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥æµ‹è¯•å†…éƒ¨ç¼“å­˜ï¼Œä½†å¯ä»¥æµ‹è¯•æ¸…ç©ºæ“ä½œ
        validator.clear_cache().await;
        
        assert_eq!(validator.cache_size().await, 0);
    }
}